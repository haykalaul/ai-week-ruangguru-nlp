{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "tr3edTKgAyvw",
      "metadata": {
        "id": "tr3edTKgAyvw"
      },
      "source": [
        "# Agenda\n",
        "1. Chatbot Overview with Langchain\n",
        "2. Spotify Songs Recommender with faiss vector database\n",
        "  - dataset: https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs?select=spotify_songs.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aRkUSvAZDV1-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRkUSvAZDV1-",
        "outputId": "18059d9d-448c-4787-db0c-2bef236877bb"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jwhZBOwZA6rC",
      "metadata": {
        "id": "jwhZBOwZA6rC"
      },
      "source": [
        "# 1.0 Chatbot Overview with Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nqg2pDZ45F5o",
      "metadata": {
        "id": "Nqg2pDZ45F5o"
      },
      "source": [
        "- source: <strong>langchain/chatbots</strong> with modification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee7f95e4",
      "metadata": {
        "id": "ee7f95e4"
      },
      "source": [
        "## Use case\n",
        "\n",
        "Chatbots are one of the central LLM use-cases. The core features of chatbots are that they can have long-running conversations and have access to information that users want to know about.\n",
        "\n",
        "Aside from basic prompting and LLMs, memory and retrieval are the core components of a chatbot. Memory allows a chatbot to remember past interactions, and retrieval provides a chatbot with up-to-date, domain-specific information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff48f490",
      "metadata": {
        "id": "ff48f490"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The chat model interface is based around messages rather than raw text. Several components are important to consider for chat:\n",
        "\n",
        "* `chat model`: See [here](/docs/integrations/chat) for a list of chat model integrations and [here](/docs/modules/model_io/chat) for documentation on the chat model interface in LangChain. You can use `LLMs` (see [here](/docs/modules/model_io/llms)) for chatbots as well, but chat models have a more conversational tone and natively support a message interface.\n",
        "* `prompt template`: Prompt templates make it easy to assemble prompts that combine default messages, user input, chat history, and (optionally) additional retrieved context.\n",
        "* `memory`: [See here](/docs/modules/memory/) for in-depth documentation on memory types\n",
        "* `retriever` (optional): [See here](/docs/modules/data_connection/retrievers) for in-depth documentation on retrieval systems. These are useful if you want to build a chatbot with domain-specific knowledge.\n",
        "\n",
        "## Quickstart\n",
        "\n",
        "Here's a quick preview of how we can create chatbot interfaces. First let's install some dependencies and set the required credentials:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K6je_iDZ5lyh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6je_iDZ5lyh",
        "outputId": "766015ce-9094-48ff-b5cd-0355edce50a8"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "djrm5y-u5kDf",
      "metadata": {
        "id": "djrm5y-u5kDf"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff0db09f",
      "metadata": {
        "id": "ff0db09f"
      },
      "source": [
        "## Regular Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gMCVWoU37EPS",
      "metadata": {
        "id": "gMCVWoU37EPS"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MKBkSWEe7JkB",
      "metadata": {
        "id": "MKBkSWEe7JkB"
      },
      "outputs": [],
      "source": [
        "# LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3WssNSd17Lay",
      "metadata": {
        "id": "3WssNSd17Lay"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            \"You are a nice chatbot having a conversation with a human.\"\n",
        "        ),\n",
        "        # The `variable_name` here is what must align with memory\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7gbsbsgt7O6A",
      "metadata": {
        "id": "7gbsbsgt7O6A"
      },
      "outputs": [],
      "source": [
        "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
        "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fccd6995",
      "metadata": {
        "id": "fccd6995"
      },
      "outputs": [],
      "source": [
        "conversation = LLMChain(llm=llm, prompt=prompt, verbose=True, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WESsNIdv7Tig",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WESsNIdv7Tig",
        "outputId": "495554da-e382-4ae1-8b2e-4850ee8bd08a"
      },
      "outputs": [],
      "source": [
        "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
        "conversation({\"question\": \"hi how are you\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb0cadfd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb0cadfd",
        "outputId": "bbddf01f-c562-486d-8b65-082ccceb49c7"
      },
      "outputs": [],
      "source": [
        "conversation(\n",
        "    {\"question\": \"my name is niken, i want to ask you something\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c56d6219",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c56d6219",
        "outputId": "82b988f4-881e-4526-9806-0fa877996c47"
      },
      "outputs": [],
      "source": [
        "conversation({\"question\": \"do you know natural language processing (NLP) ?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kaP6ORL0__tj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaP6ORL0__tj",
        "outputId": "49c4a639-b9f9-4cf3-f2aa-5776630d2cda"
      },
      "outputs": [],
      "source": [
        "conversation({\"question\": \"what is the different between natural language understanding and natural language generation ?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q2uAdBkyAM6G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2uAdBkyAM6G",
        "outputId": "dda6d267-eff6-4459-c2a9-6e766bd87746"
      },
      "outputs": [],
      "source": [
        "conversation({\"question\": \"who is my name ?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85YT7U0a3rsP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85YT7U0a3rsP",
        "outputId": "fb5a052d-a3f7-4f0b-d9bc-fd42f47b47ad"
      },
      "outputs": [],
      "source": [
        "conversation({\"question\": \"whos win in the battle between gojo satoru vs ryomen sukuna ?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X06tkaKi3nkq",
      "metadata": {
        "id": "X06tkaKi3nkq"
      },
      "source": [
        "## retriever conversation\n",
        "- add new context about gojo vs sukana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GPKacWai36c8",
      "metadata": {
        "id": "GPKacWai36c8"
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\"https://beebom.com/jujutsu-kaisen-gojo-vs-sukuna/\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9h8Y3OW-4D5M",
      "metadata": {
        "id": "9h8Y3OW-4D5M"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_qdL0Oj_Mqz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_qdL0Oj_Mqz",
        "outputId": "fbb323b4-2bf2-4419-a2a1-d734de5322ba"
      },
      "outputs": [],
      "source": [
        "embd = embedding=OpenAIEmbeddings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sBIXp3Z_4STq",
      "metadata": {
        "id": "sBIXp3Z_4STq"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "qa_retriever = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mEX9DIE54xq2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEX9DIE54xq2",
        "outputId": "c19ac30d-2b61-469a-d8f5-1c459ed9343b"
      },
      "outputs": [],
      "source": [
        "qa_retriever(\"whos win in the battle between gojo satoru vs ryomen sukuna ?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XOBfMUSDAY0W",
      "metadata": {
        "id": "XOBfMUSDAY0W"
      },
      "source": [
        "# 2.0 Similarity Search using Faiss\n",
        "- https://github.com/facebookresearch/faiss\n",
        "- https://python.langchain.com/docs/integrations/vectorstores/faiss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5VeV1jeXFteE",
      "metadata": {
        "id": "5VeV1jeXFteE"
      },
      "source": [
        "In this project, we will utilize the Faiss vector database, a powerful library for similarity search and recommendation, to create our song recommendation system. Faiss allows us to efficiently search through vast amounts of data to find courses that closely match the ones you’ve enjoyed or are interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff8925f-4c21-4680-a9cd-3670ad4852b3",
      "metadata": {
        "id": "1ff8925f-4c21-4680-a9cd-3670ad4852b3"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5BeRnQFKBtTA",
      "metadata": {
        "id": "5BeRnQFKBtTA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import faiss\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TP9JpZbWCtWn",
      "metadata": {
        "id": "TP9JpZbWCtWn"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/NLP_AI_Week_Ruangguru/spotify_songs.csv').dropna().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cb8-F7tFDhLO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Cb8-F7tFDhLO",
        "outputId": "ec953e9a-883e-4194-deab-929c296d0f98"
      },
      "outputs": [],
      "source": [
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "awseJWkAguKP",
      "metadata": {
        "id": "awseJWkAguKP"
      },
      "outputs": [],
      "source": [
        "data_clean = data[['track_name', 'track_artist']].drop_duplicates().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43dMer50Djme",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43dMer50Djme",
        "outputId": "d6a04175-e714-4f51-b96b-bff66bc5a119"
      },
      "outputs": [],
      "source": [
        "data_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6USkF_P2DkmD",
      "metadata": {
        "id": "6USkF_P2DkmD"
      },
      "outputs": [],
      "source": [
        "#create corpus\n",
        "data_clean['corpus'] = data_clean['track_artist'] + \" \" + data_clean['track_name']\n",
        "\n",
        "song_corpus = data_clean['corpus']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mrBtJUf3Dq8B",
      "metadata": {
        "id": "mrBtJUf3Dq8B"
      },
      "outputs": [],
      "source": [
        "#vectorization\n",
        "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,3), min_df=5)\n",
        "X = vectorizer.fit_transform(song_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LfZ8KJm2gXJv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfZ8KJm2gXJv",
        "outputId": "09c487bb-7635-4513-a625-50e70b54ac9a"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yd3qGc1hD4ig",
      "metadata": {
        "id": "yd3qGc1hD4ig"
      },
      "outputs": [],
      "source": [
        "#convert sparse matrix to numpy array\n",
        "X_array = np.float32(X.toarray())\n",
        "\n",
        "# create vector database index\n",
        "index = faiss.IndexFlatL2(X_array.shape[1])\n",
        "\n",
        "# add vectors to the index\n",
        "index.add(X_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rgn3htPND8PV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgn3htPND8PV",
        "outputId": "a5c20511-68e0-421c-b3b8-2512ca83f8d2"
      },
      "outputs": [],
      "source": [
        "# testing search\n",
        "search_text = [\"coldplay\"]\n",
        "search_text_vector = vectorizer.transform(search_text)\n",
        "search_text_vector_array = np.float32(search_text_vector.toarray())\n",
        "\n",
        "distances, indices = index.search(search_text_vector_array, 5)\n",
        "\n",
        "for song_index in indices[0]:\n",
        "    print(f\"Song Title: {data_clean['track_name'][song_index]} from {data_clean['track_artist'][song_index]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8-og6j1VEGJU",
      "metadata": {
        "id": "8-og6j1VEGJU"
      },
      "outputs": [],
      "source": [
        "#cerate function\n",
        "def recommend_course(title):\n",
        "    search_text = [title]\n",
        "    search_text_vector = vectorizer.transform(search_text)\n",
        "    search_text_vector_array = np.float32(search_text_vector.toarray())\n",
        "    distances, indices = index.search(search_text_vector_array, 5)\n",
        "\n",
        "    n_1 = f\"Song Title: {data_clean['track_name'][indices[0][0]]} from {data_clean['track_artist'][indices[0][0]]}\"\n",
        "    n_2 = f\"Song Title: {data_clean['track_name'][indices[0][1]]} from {data_clean['track_artist'][indices[0][1]]}\"\n",
        "    n_3 = f\"Song Title: {data_clean['track_name'][indices[0][2]]} from {data_clean['track_artist'][indices[0][2]]}\"\n",
        "\n",
        "    return n_1, n_2, n_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3Mam0O3hER0n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mam0O3hER0n",
        "outputId": "a906814b-f7fe-4b52-997d-6bbc73e6bd58"
      },
      "outputs": [],
      "source": [
        "recommend_course(\"chainsmokers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7rb31VmBElsl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rb31VmBElsl",
        "outputId": "408ab3c7-4d16-4c6e-c456-6be4fc72b9cd"
      },
      "outputs": [],
      "source": [
        "recommend_course(\"coldplay\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YJfEWqxeEovX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfEWqxeEovX",
        "outputId": "39c1325b-b497-4652-b269-53ef0130dcd2"
      },
      "outputs": [],
      "source": [
        "recommend_course(\"Denny Caknan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xtAifXlGErjk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtAifXlGErjk",
        "outputId": "eede8703-d68a-40f2-8d05-93d88e05c150"
      },
      "outputs": [],
      "source": [
        "recommend_course(\"Happy Asmara\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GZGhJslsiVlQ",
      "metadata": {
        "id": "GZGhJslsiVlQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
